# Configuration file for code-switching predictability analysis

# Data settings
data:
  # Path to directory containing EAF files
  # Update this to point to your data directory
  path: "./raw_data"

# Processing settings
processing:
  # Minimum number of words required to keep a sentence
  # Sentences with fewer words will be filtered out
  min_sentence_words: 2

# Translation settings
translation:
  # NLLB model settings (free, local translation)
  model: "facebook/nllb-200-3.3B" 
  # Options:
  # facebook/nllb-200-distilled-600M
  # facebook/nllb-200-distilled-1.3B
  # facebook/nllb-200-3.3B
  device: "cuda"
  
  # Whether to use caching for translations
  use_cache: true
  
  # Directory for translation cache
  cache_dir: "cache/translations"

# Analysis settings
analysis:
  # Minimum number of Cantonese words required at sentence start
  # for inclusion in analysis dataset
  min_cantonese_words: 2
  
  # Window sizes for POS matching around switch points
  # List of window sizes to analyze (creates separate dataset for each)
  window_sizes: [1, 2, 3]
  
  # Minimum Levenshtein similarity threshold for matches (0-1)
  similarity_threshold: 0.4
  
  # Parallel processing settings
  parallel:
    # Number of CPU cores to leave free. If null, uses all available cores (leaves 0 free).
    # Set to a number to reserve that many cores for other tasks.
    # Example: On an 8-core system, num_workers=2 means use 6 workers, leaving 2 cores free.
    num_workers: null
  
  # Batch processing settings
  # Number of sentences per batch. If null, processes all sentences at once.
  batch_size: null
  
  # Directory for saving batch checkpoints (relative to project root)
  # If null, no checkpoints are saved.
  checkpoint_dir: null

# Discourse context settings
context:
  # List of context lengths to analyze (in number of previous sentences)
  # Surprisal will be calculated for each length, creating separate columns
  # Matching script will automatically store max(context_lengths) sentences
  context_lengths: [1, 2, 3]
  
  # Minimum number of context sentences required to include sentence in analysis
  # Sentences with fewer context sentences will still be included but flagged
  min_required_sentences: 2
  
  # Minimum translation quality for context (ratio of successfully translated words)
  # Context with quality below this threshold will be flagged as invalid
  min_translation_quality: 0.3

# Experiment settings
experiment:
  # HuggingFace model for masked LM surprisal calculation
  # Default: hon9kon9ize/bert-large-cantonese (Cantonese BERT)
  masked_model: "hon9kon9ize/bert-large-cantonese"
  
  # HuggingFace model for autoregressive LM surprisal calculation
  # Options: uer/gpt2-chinese-cluecorpussmall (small), hon9kon9ize/CantoneseLLMChat-v1.0-7B (large)
  autoregressive_model: "hon9kon9ize/CantoneseLLMChat-v1.0-7B"
  
  # Use 4-bit quantization for autoregressive model (saves memory for large models)
  # Set to true for 7B+ models, false for small models
  use_4bit_quantization: true
  
  # Device to use for surprisal calculation
  device: "cuda"
  
  # Output subdirectory for main experiment results
  output_subdir: "main_experiment"
  
  # Statistical testing alpha level
  alpha: 0.05

# Output settings
output:
  # Base directory for all results
  results_dir: "results"
  
  # Base directory for all figures
  figures_dir: "figures"
  
  # Results subdirectories
  results:
    # Directory for preprocessing CSV files
    preprocessing_dir: "results/preprocessing"
    # Directory for matching analysis results
    matching_dir: "results/matching"
    # Directory for surprisal experiment results
    surprisal_dir: "results/surprisal"
  
  # Figures subdirectories
  figures:
    # Directory for preprocessing figures
    preprocessing_dir: "figures/preprocessing"
    # Directory for matching analysis figures
    matching_dir: "figures/matching"
    # Directory for surprisal experiment figures
    surprisal_dir: "figures/surprisal"
  
  # Output filename for CSV with fillers included in pattern analysis
  csv_with_fillers: "code_switching_WITH_fillers.csv"
  
  # Output filename for CSV with fillers excluded from pattern analysis
  csv_without_fillers: "code_switching_WITHOUT_fillers.csv"
  
  # Output filename for CSV with ALL sentences (monolingual + code-switched)
  csv_all_sentences: "all_sentences.csv"
  
  # Output filenames for monolingual sentences
  csv_cantonese_mono_with_fillers: "cantonese_monolingual_WITH_fillers.csv"
  csv_cantonese_mono_without_fillers: "cantonese_monolingual_WITHOUT_fillers.csv"
  csv_english_mono_with_fillers: "english_monolingual_WITH_fillers.csv"
  csv_english_mono_without_fillers: "english_monolingual_WITHOUT_fillers.csv"
  
  # Output filename for translated code-switched sentences
  csv_cantonese_translated: "cantonese_translated_WITHOUT_fillers.csv"

