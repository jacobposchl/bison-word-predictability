# Matching Pipeline Methodology

## Overview

The matching pipeline is a critical component of the word predictability analysis that identifies monolingual Cantonese sentences that are structurally similar to code-switched sentences. This allows for controlled comparison between code-switched and monolingual contexts to study word predictability effects.

**Script Location:** [`scripts/matching/matching.py`](../scripts/matching/matching.py)

**Purpose:** Find monolingual Cantonese sentences with similar syntactic structure (Part-of-Speech sequences) around switch points in code-switched sentences.

---

## Table of Contents

1. [Pipeline Overview](#pipeline-overview)
2. [Prerequisites](#prerequisites)
3. [Configuration](#configuration)
4. [Detailed Pipeline Steps](#detailed-pipeline-steps)
5. [Algorithm Details](#algorithm-details)
6. [Output Files](#output-files)
7. [Reproduction Instructions](#reproduction-instructions)
8. [Technical Implementation Details](#technical-implementation-details)

---

## Pipeline Overview

The matching pipeline implements the following high-level workflow:

```
Input Data (from preprocessing):
  ├─ Translated code-switched sentences (Cantonese translations with switch points)
  ├─ Monolingual Cantonese sentences (without fillers)
  └─ All sentences (for discourse context retrieval)

Pipeline Steps:
  1. Load and validate input datasets
  2. Filter code-switched sentences (valid switch indices)
  3. Build POS cache for monolingual sentences
  4. For each window size (n=1, 2, 3):
     ├─ Extract POS windows around switch points
     ├─ Find matching monolingual sentences using Levenshtein similarity
     ├─ Rank matches by contextual relevance
     ├─ Select top-k matches per sentence
     └─ Collect statistics
  5. Create analysis datasets (one per window size)
  6. Add discourse context to analysis datasets
  7. Generate matching reports
  8. Save results

Output:
  ├─ Analysis datasets (analysis_dataset_window_{1,2,3}.csv)
  ├─ Window matching report (window_matching_report.txt)
  └─ Ready for surprisal calculation
```

---

## Prerequisites

### Required Files (from Preprocessing)

The matching pipeline requires three CSV files generated by the preprocessing pipeline:

1. **`results/preprocessing/cantonese_translated_WITHOUT_fillers.csv`**
   - Code-switched sentences translated to Cantonese
   - Each row represents a code-switched sentence with:
     - `code_switch_original`: Original mixed-language sentence
     - `cantonese_translation`: Full Cantonese translation
     - `translated_pos`: Space-separated POS tags for translation
     - `switch_index`: Word index where first C→E switch occurs
     - `pattern`: Language pattern (e.g., "C5-E3-C2")
     - `group`: Speaker group identifier
     - `participant_id`: Speaker identifier
     - `start_time`: Sentence start time (milliseconds)

2. **`results/preprocessing/cantonese_monolingual_WITHOUT_fillers.csv`**
   - Purely Cantonese monolingual sentences (fillers removed)
   - Each row contains:
     - `reconstructed_sentence`: The Cantonese sentence text
     - `pos`: Space-separated POS tags
     - `group`: Speaker group identifier
     - `participant_id`: Speaker identifier
     - `start_time`: Sentence start time (milliseconds)

3. **`results/preprocessing/all_sentences.csv`**
   - All sentences from corpus (monolingual + code-switched)
   - Used for retrieving discourse context
   - Contains same fields as above plus `pattern` field

### Software Dependencies

- Python 3.8+
- pandas
- python-Levenshtein
- pycantonese
- spacy (with en_core_web_sm model)
- tqdm
- transformers (HuggingFace)

Install dependencies:
```bash
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

---

## Configuration

All matching parameters are configured in [`config/config.yaml`](../config/config.yaml).

### Key Configuration Parameters

#### Analysis Settings
```yaml
analysis:
  # Minimum Cantonese words before code-switch
  min_cantonese_words: 2
  
  # Window sizes for POS matching (words before/after switch)
  window_sizes: [1, 2, 3]
  
  # Minimum Levenshtein similarity threshold [0, 1]
  similarity_threshold: 0.4
  
  # Parallel processing
  parallel:
    num_workers: 3  # CPU cores to leave free (null = use all)
```

**Window Size (n):** Defines how many words before and after the switch point to include in POS comparison
- n=1: Include 1 word before + switch word + 1 word after (3 words total)
- n=2: Include 2 words before + switch word + 2 words after (5 words total)  
- n=3: Include 3 words before + switch word + 3 words after (7 words total)

**Similarity Threshold:** Minimum normalized Levenshtein similarity score (0-1) for a match to be considered valid. Calculated as:
```
similarity = 1 - (edit_distance / max_sequence_length)
```

#### Context Settings
```yaml
context:
  # Number of previous sentences to include as context
  context_lengths: [1, 2, 3]
  
  # Minimum translation quality for context (word-level)
  min_translation_quality: 0.3
```

**Context Lengths:** List of k values for retrieving k previous sentences from same speaker.

**Translation Quality:** Ratio of successfully translated words to attempted words. Context with quality below this threshold is flagged as invalid but still included.

#### Translation Settings
```yaml
translation:
  model: "facebook/nllb-200-3.3B"
  device: "cuda"
  use_cache: true
  cache_dir: "cache/translations"
```

Used for translating code-switched context sentences to Cantonese.

#### Output Settings
```yaml
output:
  results:
    matching_dir: "results/matching"
  
  # Input filenames (from preprocessing)
  csv_all_sentences: "all_sentences.csv"
  csv_cantonese_mono_without_fillers: "cantonese_monolingual_WITHOUT_fillers.csv"
  csv_cantonese_translated: "cantonese_translated_WITHOUT_fillers.csv"
```

---

## Detailed Pipeline Steps

### Step 1: Load Input Datasets

**Location:** [`scripts/matching/matching.py`](../scripts/matching/matching.py), lines 67-87

```python
# Load translated code-switched sentences
translated_csv = preprocessing_dir / config.get('output.csv_cantonese_translated')
translated_df = pd.read_csv(translated_csv)

# Load monolingual Cantonese sentences  
monolingual_csv = preprocessing_dir / config.get('output.csv_cantonese_mono_without_fillers')
monolingual_df = pd.read_csv(monolingual_csv)

# Load all sentences (for context)
all_sentences_csv = preprocessing_dir / config.get('output.csv_all_sentences')
all_sentences_df = pd.read_csv(all_sentences_csv)
```

**Purpose:** Read preprocessed CSV files containing sentence data.

**Validation:** Each file's existence is verified, raising `FileNotFoundError` if missing.

---

### Step 2: Filter Code-Switched Sentences

**Location:** [`scripts/matching/matching.py`](../scripts/matching/matching.py), lines 102-107

```python
# Filter to sentences with valid switch indices
# Pattern filtering (C >= min_cantonese followed by E) already done in preprocessing
filtered_translated_sentences = [
    s for s in translated_df.to_dict('records') 
    if s.get('switch_index', -1) >= 0
]
```

**Purpose:** Keep only sentences where a valid switch point was identified.

**Filter Criteria:**
- `switch_index >= 0`: Valid switch point exists
- Pattern already validated in preprocessing (at least `min_cantonese_words` Cantonese words followed by English)

**Why filtering?** Some sentences may have failed translation or POS tagging, resulting in invalid switch indices (-1). These cannot be matched and are excluded.

---

### Step 3: Build Monolingual POS Cache

**Location:** [`src/analysis/matching_algorithm.py`](../src/analysis/matching_algorithm.py), `build_monolingual_pos_cache()`

```python
def build_monolingual_pos_cache(monolingual_sentences: List[Dict]) -> Dict[int, List[str]]:
    """Pre-compute POS sequences for all monolingual sentences."""
    cache = {}
    for idx, mono_sent in enumerate(monolingual_sentences):
        mono_pos_str = mono_sent.get('pos', '')
        if mono_pos_str:
            cache[idx] = mono_pos_str.split()  # Split into list once
        else:
            cache[idx] = []
    return cache
```

**Purpose:** Pre-compute POS sequences to avoid repeated string splitting during matching.

**Performance Impact:** With thousands of monolingual sentences and multiple comparisons per code-switched sentence, this cache provides significant speedup by avoiding redundant string operations.

**Example:**
```python
# Without cache (repeated for each comparison):
mono_pos = "PRON VERB ADJ NOUN"
pos_list = mono_pos.split()  # Called thousands of times

# With cache (computed once):
cache[idx] = ["PRON", "VERB", "ADJ", "NOUN"]
```

---

### Step 4: Window Matching Analysis

**Location:** [`src/analysis/matching_algorithm.py`](../src/analysis/matching_algorithm.py), `analyze_window_matching()`

This is the core of the matching pipeline, executed for each window size.

#### 4.1: Configure Parallel Processing

```python
total_cores = os.cpu_count() or 1

if num_workers is None:
    actual_workers = total_cores  # Use all cores
else:
    actual_workers = max(1, total_cores - num_workers)  # Leave num_workers free
```

**Purpose:** Determine number of parallel workers based on configuration.

**Configuration Interpretation:**
- `num_workers: null` → Use all CPU cores
- `num_workers: 2` → Leave 2 cores free (on 8-core system, use 6 workers)
- Ensures at least 1 worker is used

#### 4.2: Extract POS Windows

**Location:** [`src/analysis/matching_algorithm.py`](../src/analysis/matching_algorithm.py), `find_window_matches()`, lines 268-283

For each code-switched sentence:

```python
# Parse POS sequence from translation
pos_sequence = translated_pos.split()  # e.g., ["PRON", "VERB", "ADJ", "NOUN", "VERB"]

# Validate switch_index is within bounds
if switch_index >= len(pos_sequence):
    logger.error(f"switch_index out of bounds - data quality issue")
    return []

# Extract window around switch point
window_start = max(0, switch_index - window_size)
window_end = min(len(pos_sequence), switch_index + window_size + 1)
pos_window = pos_sequence[window_start:window_end]
```

**Example with window_size=2:**

Code-switched sentence: "我 係 香港 人 but I like it here"
- Pattern: "C4-E5"
- Translation: "我 係 香港 人 但係 我 鍾意 佢 呢度"
- POS sequence: `["PRON", "VERB", "PROPN", "NOUN", "CONJ", "PRON", "VERB", "PRON", "NOUN"]`
- switch_index: 4 (position of first English word in translation)
- Window extraction:
  ```
  window_start = max(0, 4 - 2) = 2
  window_end = min(9, 4 + 2 + 1) = 7
  pos_window = ["PROPN", "NOUN", "CONJ", "PRON", "VERB"]
  ```

#### 4.3: Find Matching Monolingual Sentences

**Location:** [`src/analysis/matching_algorithm.py`](../src/analysis/matching_algorithm.py), `find_window_matches()`, lines 287-352

For each monolingual sentence, find best matching window:

```python
for idx, mono_sent in enumerate(monolingual_sentences):
    # Get POS sequence from cache
    mono_pos_seq = mono_pos_cache.get(idx, [])
    
    # Try all possible windows (sliding window approach)
    best_similarity = 0.0
    best_window = []
    best_start_idx = -1
    
    for i in range(len(mono_pos_seq) - window_len + 1):
        mono_window = mono_pos_seq[i:i + window_len]
        similarity = levenshtein_similarity(pos_window, mono_window)
        
        if similarity > best_similarity:
            best_similarity = similarity
            best_window = mono_window
            best_start_idx = i
    
    # Also try full sequence if monolingual is shorter than window
    if len(mono_pos_seq) < window_len:
        similarity = levenshtein_similarity(pos_window, mono_pos_seq)
        if similarity > best_similarity:
            best_similarity = similarity
            best_window = mono_pos_seq
            best_start_idx = 0
    
    # Keep if above threshold
    if best_similarity >= similarity_threshold and best_start_idx >= 0:
        matches.append({
            'match_sentence': mono_sent,
            'similarity': best_similarity,
            'window_size': window_size,
            'pos_window': ' '.join(pos_window),
            'matched_pos': ' '.join(best_window),
            'matched_window_start': best_start_idx,
            # ... additional metadata
        })
```

**Sliding Window Strategy:** Rather than requiring the window to be at a specific position, we slide it across the entire monolingual sentence to find the best match. This allows for flexible matching even when sentence structures differ in position.

#### 4.4: Calculate Levenshtein Similarity

**Location:** [`src/analysis/matching_algorithm.py`](../src/analysis/matching_algorithm.py), `levenshtein_similarity()`

**Algorithm:** Normalized sequence-level edit distance

```python
def levenshtein_similarity(seq1: List[str], seq2: List[str]) -> float:
    """Calculate normalized Levenshtein similarity."""
    # Calculate minimum edit operations (insertions, deletions, substitutions)
    edit_dist = _sequence_edit_distance(seq1, seq2)
    
    # Normalize by maximum sequence length
    max_len = max(len(seq1), len(seq2))
    similarity = 1.0 - (edit_dist / max_len) if max_len > 0 else 0.0
    
    return max(0.0, similarity)
```

**Edit Distance Implementation:** Uses dynamic programming to compute minimum number of operations needed to transform one sequence into another.

**Example:**
```python
seq1 = ["PRON", "VERB", "NOUN"]
seq2 = ["PRON", "VERB", "ADJ", "NOUN"]

# Edit distance = 1 (insert "ADJ")
# Max length = 4
# Similarity = 1 - (1/4) = 0.75
```

**Why Sequence-Level?** We compare POS tag sequences, not character strings. Each POS tag is treated as an atomic unit.

#### 4.5: Rank Matches by Context

**Location:** [`src/analysis/matching_algorithm.py`](../src/analysis/matching_algorithm.py), `rank_matches_by_context()`

Matches are ranked by contextual relevance using a hierarchical priority system with context-dependent tertiary ranking:

```python
def rank_matches_by_context(matches: List[Dict], source_sentence: Dict) -> List[Dict]:
    """
    Rank matches by contextual relevance:
    - Same speaker: time proximity (closer = more relevant)
    - Different speaker: similarity score (higher = more relevant)
    """
    
    def sort_key(match: Dict) -> Tuple[int, int, float]:
        # Priority 1: Same speaker (0 if same, 1 if different)
        same_speaker_priority = 0 if match_speaker == source_speaker else 1
        
        # Priority 2: Same group (0 if same, 1 if different)  
        same_group_priority = 0 if match_group == source_group else 1
        
        # Priority 3: Context-dependent metric
        if match_speaker == source_speaker:
            # Same speaker: rank by time proximity (lower = better)
            tertiary_metric = abs(match_time - source_time)
        else:
            # Different speaker: rank by similarity (negate so higher similarity = lower value)
            tertiary_metric = -similarity
        
        return (same_speaker_priority, same_group_priority, tertiary_metric)
    
    return sorted(matches, key=sort_key)
```

**Ranking Rationale:**
1. **Same speaker first:** A speaker's own utterances are the most relevant comparison (speaker-specific patterns)
2. **Then same group:** Speakers from same group share linguistic patterns
3. **Then context-dependent ranking:**
   - **Same speaker:** Time proximity matters (closer utterances are more contextually relevant)
   - **Different speaker:** Similarity matters (more similar POS patterns are more relevant)

**Why This Strategy?**
- **Same speaker + time proximity:** Captures discourse continuity and topic coherence within a speaker's conversation
- **Different speaker + similarity:** Finds alternative ways to express the same syntactic structure across speakers

**Example Ranking:**
```
Code-switched sentence: Speaker A, Group 1, Time 1000ms

Matches (before ranking):
1. Speaker B, Group 1, Similarity 0.85
2. Speaker C, Group 1, Similarity 0.92
3. Speaker A, Group 1, Time 5000ms, Similarity 0.80
4. Speaker A, Group 1, Time 1500ms, Similarity 0.75

After ranking:
1. Speaker A, Group 1, Time 1500ms, Similarity 0.75  (same speaker, closer time)
2. Speaker A, Group 1, Time 5000ms, Similarity 0.80  (same speaker, farther time)
3. Speaker C, Group 1, Similarity 0.92                (different speaker, higher similarity)
4. Speaker B, Group 1, Similarity 0.85                (different speaker, lower similarity)
```

#### 4.6: Select Top-k Matches

**Location:** [`src/analysis/matching_algorithm.py`](../src/analysis/matching_algorithm.py), `_process_single_cs_sentence()`, line 439

```python
# After ranking by context
ranked_matches = rank_matches_by_context(matches, cs_sent)

# Keep only top-k matches for storage
top_matches = ranked_matches[:top_k]  # Default: top_k = 5
```

**Purpose:** Store only the most relevant matches to reduce memory/storage while preserving best matches.

**Statistics Collection:** Before truncation, statistics (total matches, average similarity) are collected from ALL matches, not just top-k. This ensures accurate reporting.

#### 4.7: Parallel Processing

**Location:** [`src/analysis/matching_algorithm.py`](../src/analysis/matching_algorithm.py), `analyze_window_matching()`, lines 550-568

```python
# Prepare arguments for each code-switched sentence
worker_args = [
    (cs_sent, monolingual_sentences, window_size, similarity_threshold, 
     mono_pos_cache, top_k)
    for cs_sent in translated_sentences
]

# Process in parallel or sequentially
if num_workers == 1:
    # Sequential with progress bar
    processing_results = []
    for args in tqdm(worker_args, desc=f"Window n={window_size}"):
        result = _process_single_cs_sentence(args)
        processing_results.append(result)
else:
    # Parallel with multiprocessing
    with multiprocessing.Pool(processes=num_workers) as pool:
        processing_results = list(tqdm(
            pool.imap(_process_single_cs_sentence, worker_args),
            total=len(worker_args),
            desc=f"Window n={window_size}"
        ))
```

**Worker Function:** `_process_single_cs_sentence()` processes one code-switched sentence independently, making it suitable for parallelization.

**Progress Tracking:** `tqdm` provides real-time progress updates regardless of parallel/sequential processing.

#### 4.8: Collect Statistics

**Location:** [`src/analysis/matching_algorithm.py`](../src/analysis/matching_algorithm.py), `analyze_window_matching()`, lines 570-620

```python
# Aggregate results from all workers
for cs_sent, sent_detailed_matches, has_matches, sent_similarity_scores in processing_results:
    if has_matches:
        sentences_with_matches += 1
        detailed_matches.extend(sent_detailed_matches)
        similarity_scores.extend(sent_similarity_scores)

# Calculate statistics
total_sentences = len(translated_sentences)
match_rate = sentences_with_matches / total_sentences
total_matches = len(detailed_matches)
avg_matches = total_matches / total_sentences
avg_similarity = sum(similarity_scores) / len(similarity_scores)
```

**Collected Metrics:**
- `total_sentences`: Number of code-switched sentences processed
- `sentences_with_matches`: Number that found at least one match
- `match_rate`: Percentage with matches
- `total_matches`: Total number of detailed matches (all top-k across all sentences)
- `avg_matches_per_sentence`: Average matches per sentence
- `avg_similarity`: Mean similarity score across all matches
- `similarity_scores`: Full list of scores for distribution analysis

---

### Step 5: Create Analysis Datasets

**Location:** [`scripts/matching/matching.py`](../scripts/matching/matching.py), lines 124-145

**Function:** [`src/data/analysis_dataset.py`](../src/data/analysis_dataset.py), `create_analysis_dataset()`

For each window size, create a dataset with one row per code-switched sentence:

```python
for window_size in window_sizes:
    # Create analysis dataset for this window size
    analysis_df = create_analysis_dataset(
        config,
        filtered_translated_sentences,
        window_results,
        all_sentences_df,
        translator,
        window_size=window_size
    )
    
    # Save with window size in filename
    analysis_csv_path = output_dir / f"analysis_dataset_window_{window_size}.csv"
    analysis_df.to_csv(analysis_csv_path, index=False, encoding='utf-8-sig')
```

#### 5.1: Build Analysis Rows

**Location:** [`src/data/analysis_dataset.py`](../src/data/analysis_dataset.py), `create_analysis_dataset()`, lines 326-386

```python
# Extract detailed matches for this window size
window_key = f'window_{window_size}'
detailed_matches = window_results[window_key]['detailed_matches']

# Group matches by code-switched sentence
sentence_data = {}
for match in detailed_matches:
    cs_translation = match['cs_translation']
    
    if cs_translation not in sentence_data:
        # Initialize with CS sentence data
        sentence_data[cs_translation] = {
            'cs_translation': cs_translation,
            'cs_pattern': match['cs_pattern'],
            'switch_index': match['switch_index'],
            'best_match': None,
            'all_matches': []
        }
    
    sentence_data[cs_translation]['all_matches'].append(match)
    
    # Store best match (rank 1)
    if match['rank'] == 1:
        sentence_data[cs_translation]['best_match'] = match

# Build rows with best match + statistics
for cs_translation, data in sentence_data.items():
    best_match = data['best_match']
    all_matches = data['all_matches']
    
    if best_match:  # Only include sentences with matches
        analysis_rows.append({
            # Code-switched sentence
            'cs_translation': cs_translation,
            'cs_pattern': data['cs_pattern'],
            'switch_index': data['switch_index'],
            'pos_window': data['pos_window'],
            
            # Best matched monolingual sentence
            'matched_mono': best_match['matched_sentence'],
            'matched_switch_index': best_match['matched_switch_index'],
            'cs_switch_pos': best_match['cs_switch_pos'],
            'mono_switch_pos': best_match['mono_switch_pos'],
            'similarity': best_match['similarity'],
            
            # Match statistics
            'total_matches_above_threshold': best_match['total_matches_above_threshold'],
            'matches_same_group': best_match['all_matches_same_group'],
            'matches_same_speaker': best_match['all_matches_same_speaker']
        })
```

**Key Fields:**
- **cs_translation:** Full Cantonese translation of code-switched sentence
- **matched_mono:** Best matching monolingual sentence
- **switch_index:** Position in CS translation where switch occurs
- **matched_switch_index:** Corresponding position in matched sentence (center of matched POS window)
- **cs_switch_pos / mono_switch_pos:** POS tags at switch positions
- **similarity:** Levenshtein similarity score for best match
- **total_matches_above_threshold:** How many monolingual sentences matched this CS sentence
- **matches_same_group / matches_same_speaker:** How many were from same group/speaker

---

### Step 6: Add Discourse Context

**Location:** [`src/data/analysis_dataset.py`](../src/data/analysis_dataset.py), `add_context_to_analysis_dataset()`

Adds k previous sentences from the same speaker as contextual information.

#### 6.1: Build Participant Index

```python
def _build_participant_index(all_sentences_df: pd.DataFrame) -> Dict[str, pd.DataFrame]:
    """Build index of sentences grouped by participant for faster lookups."""
    index = {}
    for participant_id, group_df in all_sentences_df.groupby('participant_id'):
        # Sort by start_time for efficient lookups
        index[participant_id] = group_df.sort_values('start_time').reset_index(drop=True)
    return index
```

**Purpose:** Pre-group and sort sentences by speaker to enable efficient context retrieval.

**Performance:** Without indexing, each context lookup would require scanning all sentences. With indexing, lookups are O(log n) per speaker.

#### 6.2: Collect All Context Sentences

```python
all_cs_context_sents = []
all_mono_context_sents = []

for _, row in analysis_df.iterrows():
    # Get k previous sentences from CS sentence's speaker
    cs_context = _get_previous_sentences_indexed(
        participant_index,
        row['cs_participant'],
        row['cs_start_time'],
        num_context=max(context_lengths)  # e.g., 3
    )
    all_cs_context_sents.extend(cs_context)
    
    # Get k previous sentences from matched mono sentence's speaker
    mono_context = _get_previous_sentences_indexed(
        participant_index,
        row['matched_participant'],
        row['matched_start_time'],
        num_context=max(context_lengths)
    )
    all_mono_context_sents.extend(mono_context)
```

**Context Retrieval Logic:**

```python
def _get_previous_sentences_indexed(
    participant_index: Dict[str, pd.DataFrame],
    participant: str,
    start_time: float,
    num_previous: int = 3
) -> List[Dict]:
    """Get k previous sentences using pre-built index."""
    participant_df = participant_index[participant]
    
    # Find all rows with start_time < current start_time
    mask = participant_df['start_time'] < start_time
    previous = participant_df[mask].tail(num_previous)
    
    return [{
        'sentence': row['reconstructed_sentence'],
        'pattern': row['pattern']
    } for _, row in previous.iterrows()]
```

**Example:**
```
Speaker A's sentences (sorted by time):
  [100ms] "我 去 學校"      ← 3rd previous
  [200ms] "今日 天氣 好"    ← 2nd previous  
  [300ms] "我 想 食飯"      ← 1st previous
  [400ms] "但係 I'm tired"  ← Current sentence (CS)

Context retrieved: sentences at 100ms, 200ms, 300ms
```

#### 6.3: Batch Translate Context

**Location:** [`src/data/analysis_dataset.py`](../src/data/analysis_dataset.py), `_batch_translate_context_sentences()`

Context sentences may be code-switched, pure English, or pure Cantonese. They must be translated to Cantonese for consistency.

```python
# Group sentences by type
cs_sentences = []      # Code-switched: require pattern-aware translation
english_sentences = [] # Pure English: require full translation
cantonese_sentences = [] # Pure Cantonese: no translation needed

for (sentence, pattern) in unique_sentences:
    segments = parse_pattern_segments(pattern)
    languages = {lang for lang, _ in segments}
    
    if 'C' in languages and 'E' in languages:
        cs_sentences.append((sentence, pattern))
    elif languages == {'E'}:
        english_sentences.append((sentence, pattern))
    elif languages == {'C'}:
        # Already Cantonese, no translation needed
        translation_cache[(sentence, pattern)] = sentence

# Batch translate code-switched context
if cs_sentences:
    cs_results = translator.translate_batch(cs_sentences, patterns, words_list)
    for (sentence, pattern), result in zip(cs_sentences, cs_results):
        translation_cache[(sentence, pattern)] = result['translated_sentence']

# Translate English sentences
for sentence, pattern in english_sentences:
    cantonese = translator.translate_english_to_cantonese(sentence)
    translation_cache[(sentence, pattern)] = cantonese
```

**Batching Benefits:** 
- Code-switched sentences: Translated in batches using GPU efficiently
- English sentences: Translated individually (typically fewer)
- Cantonese sentences: No translation needed (cached as-is)

#### 6.4: Clean Translations and Track Quality

```python
cleaned_cache = {}
quality_stats = {}  # (sentence, pattern) -> (attempted_words, completed_words)

for (sentence, pattern), cantonese in translation_cache.items():
    # Remove fillers
    cantonese = remove_fillers_from_text(cantonese, lang=None)
    
    # Count words before cleaning
    words_before = [w for w in cantonese.split() if w]
    attempted_words = len(words_before)
    
    # Remove UNKNOWN tokens and English words
    translated_words = [
        w for w in words_before
        if w not in ['UNKNOWN', 'UNK', ''] and not is_english_word(w)
    ]
    completed_words = len(translated_words)
    
    # Track word-level quality
    quality_stats[(sentence, pattern)] = (attempted_words, completed_words)
    
    # Store cleaned translation
    cleaned_cache[(sentence, pattern)] = ' '.join(translated_words)
```

**Quality Calculation:**
```
quality = completed_words / attempted_words

attempted_words: Words after filler removal (includes UNKNOWN, English)
completed_words: Successfully translated Cantonese words
```

**Example:**
```
Original: "我 係 UNKNOWN 人 but I like it"
After cleaning: "我 係 人"

attempted_words = 7
completed_words = 3
quality = 3/7 = 0.43
```

**Quality Threshold:** Configured as `context.min_translation_quality: 0.3`
- If quality < 0.3, context is flagged as `cs_context_valid: False`
- Context is still included in dataset but marked for potential exclusion in analysis

#### 6.5: Assemble Context from Cache

```python
def _assemble_context_from_cache(
    context_sentences: List[Dict],
    translation_cache: Dict,
    quality_stats: Dict,
    min_quality: float = 0.3
) -> Dict:
    """Assemble context and calculate quality."""
    
    translations = []
    total_attempted = 0
    total_completed = 0
    
    for sent_dict in context_sentences:
        sentence = sent_dict['sentence']
        pattern = sent_dict['pattern']
        
        # Look up in cache
        cantonese = translation_cache[(sentence, pattern)]
        attempted, completed = quality_stats[(sentence, pattern)]
        
        total_attempted += attempted
        total_completed += completed
        
        if cantonese:
            translations.append(cantonese)
    
    # Join with delimiter
    full_context = ' ||| '.join(translations)
    
    # Calculate overall quality
    quality_score = total_completed / max(total_attempted, 1)
    is_valid = quality_score >= min_quality
    
    return {
        'translated_context': full_context,
        'quality_score': quality_score,
        'is_valid': is_valid,
        'num_context_sentences': len(context_sentences)
    }
```

**Context Delimiter:** `' ||| '` (three pipes with spaces)
- Preserves sentence boundaries
- Easily parseable for downstream analysis
- Example: `"我 去 學校 ||| 今日 天氣 好 ||| 我 想 食飯"`

**Aggregate Quality:** Quality is calculated across all context sentences combined (total completed words / total attempted words), not averaged per sentence.

#### 6.6: Add Context to DataFrame

```python
for _, row in analysis_df.iterrows():
    # Get context sentences
    cs_context_sents = _get_previous_sentences_indexed(...)
    mono_context_sents = _get_previous_sentences_indexed(...)
    
    # Assemble from cache
    cs_context_result = _assemble_context_from_cache(
        cs_context_sents, cs_translation_cache, cs_quality_stats, min_quality
    )
    mono_context_result = _assemble_context_from_cache(
        mono_context_sents, mono_translation_cache, mono_quality_stats, min_quality
    )
    
    # Add to row
    row_data.update({
        'cs_context': cs_context_result['translated_context'],
        'cs_context_valid': cs_context_result['is_valid'],
        'mono_context': mono_context_result['translated_context'],
        'mono_context_valid': mono_context_result['is_valid']
    })
```

**Final Context Columns:**
- `cs_context`: Joined Cantonese translations of k previous sentences before CS sentence
- `cs_context_valid`: Boolean indicating if quality >= threshold
- `mono_context`: k previous sentences before matched monolingual sentence (already Cantonese)
- `mono_context_valid`: Boolean indicating if quality >= threshold

**Context Statistics Logging:**
```
Context statistics:
  CS context valid: 234 / 300
  Mono context valid: 287 / 300
  Both contexts valid: 210 / 300
```

---

### Step 7: Generate Matching Report

**Location:** [`src/plots/matching/report_generator.py`](../src/plots/matching/report_generator.py), `generate_window_matching_report()`

Creates a comprehensive text report summarizing matching results across all window sizes.

**Report Sections:**

#### Section 1: Overall Statistics Table
```
Window   Total  Matched   Match %      Total  Avg/Sent   Avg Sim
Size     Sents    Sents                Matches
------------------------------------------------------------------------
   1       450      423      94.0%       2115      4.70      0.652
   2       450      438      97.3%       2190      4.87      0.721
   3       450      441      98.0%       2205      4.90      0.758
```

#### Section 2: Detailed Statistics Per Window
```
Window Size: 2
  Total sentences processed: 450
  Sentences with matches: 438 (97.3%)
  Sentences without matches: 12 (2.7%)
  Total matches found: 2190
  Average matches per sentence: 4.87
  Similarity score statistics:
    Mean: 0.721
    Median: 0.733
    Min: 0.400
    Max: 1.000
    Std Dev: 0.142
  Matches above threshold (0.40): 2190 (100.0%)
```

#### Section 3: Comparison Across Windows
```
Best match rate: Window size 3 (98.0%)
Best average similarity: Window size 3 (0.758)
```

**Purpose:** 
- Quality control: Verify matching is working as expected
- Parameter tuning: Compare window sizes to select optimal
- Documentation: Record exact statistics for methods section

---

### Step 8: Save Results

**Location:** [`scripts/matching/matching.py`](../scripts/matching/matching.py), lines 137-157

```python
# Create output directory
output_dir.mkdir(parents=True, exist_ok=True)

# Save analysis dataset for each window size
for window_size in window_sizes:
    analysis_df = create_analysis_dataset(...)
    
    analysis_csv_path = output_dir / f"analysis_dataset_window_{window_size}.csv"
    analysis_df.to_csv(analysis_csv_path, index=False, encoding='utf-8-sig')
    logger.info(f"Saved: {analysis_csv_path} ({len(analysis_df)} rows)")

# Save window matching report
window_report = generate_window_matching_report(window_results, similarity_threshold)
window_report_path = output_dir / "window_matching_report.txt"
with open(window_report_path, 'w', encoding='utf-8') as f:
    f.write(window_report)

logger.info(f"Analysis complete! Results saved to: {output_dir}")
logger.info(f"Created {len(window_sizes)} analysis datasets")
```

**Output Files:**
- `results/matching/analysis_dataset_window_1.csv`
- `results/matching/analysis_dataset_window_2.csv`
- `results/matching/analysis_dataset_window_3.csv`
- `results/matching/window_matching_report.txt`

---

## Algorithm Details

### Levenshtein Edit Distance Algorithm

**Purpose:** Calculate minimum number of edit operations (insertions, deletions, substitutions) to transform one sequence into another.

**Implementation:** [`src/analysis/matching_algorithm.py`](../src/analysis/matching_algorithm.py), `_sequence_edit_distance()`

```python
def _sequence_edit_distance(seq1: List[str], seq2: List[str]) -> int:
    """Calculate edit distance using dynamic programming."""
    m, n = len(seq1), len(seq2)
    
    # Initialize DP matrix
    dp = [[0] * (n + 1) for _ in range(m + 1)]
    
    # Base cases: distance from empty sequence
    for i in range(m + 1):
        dp[i][0] = i  # Delete all from seq1
    for j in range(n + 1):
        dp[0][j] = j  # Insert all from seq2
    
    # Fill matrix using recurrence relation
    for i in range(1, m + 1):
        for j in range(1, n + 1):
            if seq1[i-1] == seq2[j-1]:
                # Characters match, no operation needed
                dp[i][j] = dp[i-1][j-1]
            else:
                # Take minimum of three operations
                dp[i][j] = 1 + min(
                    dp[i-1][j],      # Delete from seq1
                    dp[i][j-1],      # Insert to seq1
                    dp[i-1][j-1]     # Substitute
                )
    
    return dp[m][n]
```

**Example Trace:**

```
seq1 = ["PRON", "VERB"]
seq2 = ["PRON", "ADV", "VERB"]

DP Matrix:
       ""    PRON  ADV   VERB
""     0     1     2     3
PRON   1     0     1     2
VERB   2     1     1     1

Edit distance = 1 (insert "ADV")
```

**Time Complexity:** O(m × n) where m, n are sequence lengths  
**Space Complexity:** O(m × n)

### Normalized Similarity Calculation

```python
similarity = 1 - (edit_distance / max_length)
```

**Normalization Rationale:**
- Longer sequences naturally have higher edit distances
- Normalization makes similarity scores comparable across different lengths
- Range: [0, 1] where 1 = identical, 0 = completely different

**Examples:**

| Seq1 | Seq2 | Edit Dist | Max Len | Similarity |
|------|------|-----------|---------|------------|
| ["A", "B"] | ["A", "B"] | 0 | 2 | 1.000 |
| ["A", "B"] | ["A", "C"] | 1 | 2 | 0.500 |
| ["A", "B"] | ["C", "D"] | 2 | 2 | 0.000 |
| ["A", "B", "C"] | ["A", "B"] | 1 | 3 | 0.667 |

### POS Tagging

**Cantonese:** [`src/analysis/pos_tagging.py`](../src/analysis/pos_tagging.py), `pos_tag_cantonese()`

Uses **PyCantonese** library:
```python
def pos_tag_cantonese(sentence: str) -> List[Tuple[str, str]]:
    """Tag Cantonese using PyCantonese."""
    words = pycantonese.segment(sentence)  # Word segmentation
    tagged = pycantonese.pos_tag(words)    # POS tagging
    return [(word, pos) for word, pos in tagged if word.strip()]
```

**Example:**
```python
pos_tag_cantonese("我係香港人")
# Output: [('我', 'PRON'), ('係', 'VERB'), ('香港人', 'NOUN')]
```

**English:** [`src/analysis/pos_tagging.py`](../src/analysis/pos_tagging.py), `pos_tag_english()`

Uses **spaCy** library:
```python
def pos_tag_english(sentence: str) -> List[Tuple[str, str]]:
    """Tag English using spaCy."""
    nlp = spacy.load("en_core_web_sm")
    doc = nlp(sentence)
    return [(token.text, token.pos_) for token in doc 
            if not token.is_space and not token.is_punct]
```

**Example:**
```python
pos_tag_english("I am from Hong Kong")
# Output: [('I', 'PRON'), ('am', 'AUX'), ('from', 'ADP'), 
#          ('Hong', 'PROPN'), ('Kong', 'PROPN')]
```

**Mixed Sentences:** Segmented by pattern, then each segment tagged separately using appropriate tagger.

### Switch Point Detection

**Location:** Already computed in preprocessing pipeline

The `switch_index` represents the word position (0-based) where the first Cantonese→English switch occurs in the **translated** sentence.

**Example:**
```
Original: "我 係 香港 人 but I like it"
Pattern: "C4-E4"
Translation: "我 係 香港 人 但係 我 鍾意 佢"
POS: ["PRON", "VERB", "PROPN", "NOUN", "CONJ", "PRON", "VERB", "PRON"]
switch_index: 4 (position of first translated English word "但係")
```

**Why in translation?** The matching algorithm compares POS sequences from translations, so the switch point must correspond to the translated sequence.

---

## Output Files

### Analysis Datasets

**Files:** `results/matching/analysis_dataset_window_{1,2,3}.csv`

**Format:** CSV with UTF-8-sig encoding (supports Chinese characters in Excel)

**Columns:**

| Column | Type | Description |
|--------|------|-------------|
| `cs_translation` | str | Full Cantonese translation of code-switched sentence |
| `cs_pattern` | str | Language pattern (e.g., "C5-E3-C2") |
| `cs_group` | str | Speaker group identifier |
| `cs_start_time` | float | Sentence start time (milliseconds) |
| `switch_index` | int | Word index where code-switch occurs |
| `pos_window` | str | Space-separated POS tags from CS window |
| `matched_mono` | str | Best matched monolingual Cantonese sentence |
| `matched_group` | str | Group of matched sentence's speaker |
| `matched_start_time` | float | Matched sentence start time (milliseconds) |
| `matched_pos` | str | Space-separated POS tags from matched window |
| `matched_switch_index` | int | Corresponding position in matched sentence |
| `cs_switch_pos` | str | POS tag at switch point in CS sentence |
| `mono_switch_pos` | str | POS tag at switch point in matched sentence |
| `similarity` | float | Levenshtein similarity score [0, 1] |
| `total_matches_above_threshold` | int | Number of monolingual sentences that matched |
| `matches_same_group` | int | Matches from same speaker group |
| `matches_same_speaker` | int | Matches from same speaker |
| `cs_context` | str | k previous sentences before CS (translated to Cantonese, delimiter: ' \|\|\| ') |
| `cs_context_valid` | bool | Whether CS context meets quality threshold |
| `mono_context` | str | k previous sentences before matched mono |
| `mono_context_valid` | bool | Whether mono context meets quality threshold |

**Row Count:** One row per code-switched sentence that found at least one match

**Example Row:**
```csv
cs_translation,cs_pattern,switch_index,matched_mono,similarity,cs_context,cs_context_valid
"我 係 香港 人 但係 我 鍾意 佢","C4-E4",4,"我 係 本地 人 不過 我 鍾意 佢",0.857,"我 去 學校 ||| 今日 天氣 好",True
```

### Window Matching Report

**File:** `results/matching/window_matching_report.txt`

**Format:** Plain text report with tables and statistics

**Content:**
1. Overall statistics table comparing all window sizes
2. Detailed statistics per window size
3. Cross-window comparison (best match rate, best similarity)

**Example:**
```
================================================================================
POS WINDOW MATCHING ANALYSIS REPORT
================================================================================

This report analyzes how well we can match code-switched sentences
to monolingual Cantonese sentences using POS sequence similarity
around the switch point.

Similarity Threshold: 0.40 (Levenshtein)

1. OVERALL MATCHING STATISTICS BY WINDOW SIZE
--------------------------------------------------------------------------------

Window    Total  Matched   Match %      Total  Avg/Sent   Avg Sim
Size      Sents    Sents                Matches
--------------------------------------------------------------------------------
       1      450      423      94.0%       2115      4.70      0.652
       2      450      438      97.3%       2190      4.87      0.721
       3      450      441      98.0%       2205      4.90      0.758

...
```

**Usage:** Include statistics in research paper's methods/results section.

---

## Reproduction Instructions

### Prerequisites

1. **Complete preprocessing pipeline first:**
   ```bash
   python scripts/preprocessing/preprocess.py
   ```
   
   This generates required input files:
   - `results/preprocessing/cantonese_translated_WITHOUT_fillers.csv`
   - `results/preprocessing/cantonese_monolingual_WITHOUT_fillers.csv`
   - `results/preprocessing/all_sentences.csv`

2. **Verify configuration:**
   ```bash
   # Check config/config.yaml
   # Ensure settings match your requirements:
   #   - analysis.window_sizes: [1, 2, 3]
   #   - analysis.similarity_threshold: 0.4
   #   - context.context_lengths: [1, 2, 3]
   #   - context.min_translation_quality: 0.3
   ```

3. **Ensure dependencies installed:**
   ```bash
   pip install -r requirements.txt
   python -m spacy download en_core_web_sm
   ```

### Running the Pipeline

**Basic execution:**
```bash
python scripts/matching/matching.py
```

**With custom parallel processing:**
```bash
# Leave 2 CPU cores free (use total_cores - 2 workers)
python scripts/matching/matching.py --num-workers-free 2

# Use all CPU cores
python scripts/matching/matching.py --num-workers-free 0
```

**Expected console output:**
```
INFO: Starting POS window matching analysis...
INFO: Building monolingual POS cache...
INFO: Cached POS sequences for 3245 monolingual sentences
INFO: Analyzing 456 sentences...
INFO: Window sizes to process: [1, 2, 3]
INFO: Leaving 2 cores free, using 6 parallel workers (out of 8 total)

Analyzing window size n=1...
Window n=1: 100%|████████████| 456/456 [02:34<00:00,  2.96it/s]

Analyzing window size n=2...
Window n=2: 100%|████████████| 456/456 [02:41<00:00,  2.82it/s]

Analyzing window size n=3...
Window n=3: 100%|████████████| 456/456 [02:48<00:00,  2.71it/s]

INFO: Creating analysis datasets for each window size...

Processing window size 1...
INFO: Creating analysis dataset from pre-computed window matching results...
INFO: Processing 456 filtered sentences
INFO: Adding discourse context from previous sentences...
INFO: Context settings: 3 previous sentences, min quality 0.3
INFO: Building participant index for faster context retrieval...
INFO: Indexed sentences for 45 participants
INFO: Collecting all context sentences...
Collecting context: 100%|████████████| 423/423 [00:05<00:00, 74.2it/s]
INFO: Batch translating context sentences...
INFO: Translating 1247 unique context sentences...
Translating: 100%|████████████| 1247/1247 [01:23<00:00, 14.9it/s]
INFO: Processing rows with cached translations...
Adding context: 100%|████████████| 423/423 [00:02<00:00, 187.3it/s]
INFO: Context statistics:
  CS context valid: 398 / 423
  Mono context valid: 412 / 423
  Both contexts valid: 385 / 423
INFO: Saved: results/matching/analysis_dataset_window_1.csv (423 rows)

Processing window size 2...
[... similar output for window 2 ...]

Processing window size 3...
[... similar output for window 3 ...]

INFO: Analysis complete! Results saved to: results/matching
INFO: Created 3 analysis datasets (one per window size)
INFO: To generate figures, run: python scripts/plots/figures.py --matching
```

### Verification Steps

**1. Check output files exist:**
```bash
ls -lh results/matching/
# Should show:
#   analysis_dataset_window_1.csv
#   analysis_dataset_window_2.csv
#   analysis_dataset_window_3.csv
#   window_matching_report.txt
```

**2. Inspect report:**
```bash
cat results/matching/window_matching_report.txt
# Verify:
#   - Match rates are reasonable (>90%)
#   - Average similarities increase with window size
#   - Statistics make sense
```

**3. Check dataset structure:**
```python
import pandas as pd

df = pd.read_csv('results/matching/analysis_dataset_window_2.csv')
print(df.shape)  # Should have ~400-450 rows
print(df.columns.tolist())  # Verify all expected columns present
print(df.head())

# Verify no nulls in critical columns
assert df['cs_translation'].notna().all()
assert df['matched_mono'].notna().all()
assert df['switch_index'].notna().all()
assert df['similarity'].notna().all()

# Verify similarity scores in valid range
assert (df['similarity'] >= 0.4).all()  # Above threshold
assert (df['similarity'] <= 1.0).all()  # Max is 1.0

# Verify context columns present
assert 'cs_context' in df.columns
assert 'mono_context' in df.columns
assert 'cs_context_valid' in df.columns
assert 'mono_context_valid' in df.columns
```

**4. Validate context quality:**
```python
# Check context validity distribution
print(f"CS context valid: {df['cs_context_valid'].sum()} / {len(df)}")
print(f"Mono context valid: {df['mono_context_valid'].sum()} / {len(df)}")
print(f"Both valid: {(df['cs_context_valid'] & df['mono_context_valid']).sum()} / {len(df)}")

# Typical expected: ~90% valid context
```

### Troubleshooting

**Issue: No matches found**
```
ERROR: window_matching_report.txt shows 0% match rate
```
**Solution:** 
- Check `similarity_threshold` in config (may be too high)
- Verify preprocessing completed successfully
- Ensure POS tagging is working (check translated_pos column not empty)

**Issue: Out of memory**
```
MemoryError during parallel processing
```
**Solution:**
- Reduce `num_workers` (leave more cores free, use sequential processing)
- Process in batches (modify code to process subsets)
- Use machine with more RAM

**Issue: Context translation failures**
```
WARNING: Translation failed for English sentence...
```
**Solution:**
- Check GPU availability (`device: "cuda"` requires CUDA)
- Verify translation model downloaded correctly
- Check cache directory permissions

**Issue: Slow performance**
```
Processing taking >30 minutes
```
**Solution:**
- Increase parallel workers: `--num-workers-free 0`
- Enable translation caching: `translation.use_cache: true`
- Use GPU for translation: `device: "cuda"`
- Use smaller translation model (distilled-600M instead of 3.3B)

---

## Technical Implementation Details

### Memory Optimization

**POS Cache:** Pre-computing POS sequences avoids repeated string splitting
```python
# Without cache: O(n × m) string splits
# With cache: O(m) string splits + O(n × m) lookups

# Example: 450 CS sentences × 3000 mono sentences × 3 window sizes
# Without cache: 4,050,000 string splits
# With cache: 3,000 string splits + 4,050,000 dict lookups
```

**Context Translation Cache:** Deduplicates context sentences before translation
```python
# Typical: ~1000 unique context sentences from ~5000 total context references
# Saves: ~80% translation time
```

### Parallel Processing Strategy

**Process-based parallelism** using `multiprocessing.Pool`:
- Each worker processes one code-switched sentence independently
- No shared state between workers (POS cache is copied to each worker)
- Progress tracking via `tqdm` with `imap` for real-time updates

**Worker independence:**
```python
# Each worker receives:
worker_args = (
    cs_sent,                # Code-switched sentence
    monolingual_sentences,  # Full list (read-only)
    window_size,           # Configuration
    similarity_threshold,  # Configuration
    mono_pos_cache,        # Pre-computed cache (read-only)
    top_k                  # Configuration
)

# Worker returns:
return (cs_sent, detailed_matches, has_matches, similarity_scores)
```

**No inter-worker communication** required, enabling linear scaling with CPU cores.

### Statistical Accuracy

**Before truncation statistics:** All statistics (match counts, average similarity) are computed from ALL matches before truncating to top-k. This ensures:
- Match rates reflect all matches found, not just top-k
- Average similarity is calculated from complete distribution
- Statistical reports are accurate

**After ranking selection:** Only top-k matches are stored in output files to reduce file size while preserving most relevant matches.

### Data Quality Checks

**Switch index validation:**
```python
if switch_index >= len(pos_sequence):
    logger.error(f"switch_index out of bounds for POS sequence")
    # This indicates translation or POS tagging failure
    return []
```

**Context quality tracking:**
```python
quality_score = completed_words / attempted_words
is_valid = quality_score >= min_translation_quality

# Flags low-quality context but still includes it
# Allows downstream analysis to filter or investigate quality issues
```

**File existence validation:**
```python
if not translated_csv.exists():
    raise FileNotFoundError(f"Translated sentences CSV not found: {translated_csv}")
# Fails fast if prerequisites missing
```

### Unicode and Encoding

**CSV encoding:** UTF-8-sig (BOM) for Excel compatibility
```python
analysis_df.to_csv(analysis_csv_path, index=False, encoding='utf-8-sig')
```

**String handling:** All text processing uses Unicode strings natively
- PyCantonese: Handles Chinese characters
- spaCy: Handles English with Unicode
- Levenshtein: Works with any Unicode strings

### Determinism and Reproducibility

**Deterministic components:**
- Levenshtein edit distance: deterministic algorithm
- POS tagging: deterministic (given same model versions)
- Ranking: stable sort (consistent ordering for ties)
- Context retrieval: time-based ordering (deterministic given same timestamps)

**Non-deterministic components:**
- Parallel processing order (results are sorted after collection)
- Neural translation models (may vary slightly between runs)

**For exact reproduction:**
- Use same software versions (pycantonese, spacy, transformers)
- Use same translation model checkpoint
- Set random seeds in config (`experiment.random_seed: 42`)

---

## References

**Theoretical Background:**
- Calvillo, J., Aizawa, I., Gillon, C., & Brysbaert, M. (2020). "Norms of valence and arousal for 14,031 Spanish words." *Behavior Research Methods*.
  - Inspiration for similarity-based matching methodology

**Software Libraries:**
- PyCantonese: https://pycantonese.org/
- spaCy: https://spacy.io/
- python-Levenshtein: https://github.com/ztane/python-Levenshtein
- NLLB (No Language Left Behind): https://ai.facebook.com/research/no-language-left-behind/

**Related Documentation:**
- [Preprocessing Methodology](preprocessing_methodology.md)
- Configuration: [`config/config.yaml`](../config/config.yaml)
- Main script: [`scripts/matching/matching.py`](../scripts/matching/matching.py)
- Core algorithms: [`src/analysis/matching_algorithm.py`](../src/analysis/matching_algorithm.py)

---

## Summary

The matching pipeline is a sophisticated system that:

1. **Identifies structural similarity** between code-switched and monolingual sentences using POS sequences
2. **Accounts for context** by ranking matches by speaker identity and temporal proximity
3. **Provides discourse context** by retrieving and translating previous sentences
4. **Ensures quality** through validation, quality tracking, and comprehensive reporting
5. **Scales efficiently** using parallel processing and caching strategies

The output analysis datasets provide matched sentence pairs with controlled syntactic structure, enabling rigorous comparison of word predictability between code-switched and monolingual contexts in downstream surprisal analysis.
